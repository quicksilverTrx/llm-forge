{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/Users/sohom/Desktop/s_github/forge1')\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from src.attention.optimizations.grouped_query_attention import GroupedQueryAttention, GQAConfig\n",
    "from model_patcher import patch_attention_in_gpt2, add_rope_to_attention, remove_position_embeddings\n",
    "from train_utils import  train_epoch, evaluate, prepare_wikitext2, LanguageModelingWrapper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GQAConfig(num_query_heads=12, num_kv_heads=4, head_dim=64, dropout=0.1, max_seq_length=8192, use_bias=False)\n",
      "Using random initialization for layer 0\n",
      "Using random initialization for layer 1\n",
      "Using random initialization for layer 2\n",
      "Using random initialization for layer 3\n",
      "Using random initialization for layer 4\n",
      "Using random initialization for layer 5\n",
      "Using random initialization for layer 6\n",
      "Using random initialization for layer 7\n",
      "Using random initialization for layer 8\n",
      "Using random initialization for layer 9\n",
      "Using random initialization for layer 10\n",
      "Using random initialization for layer 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/2295 [00:39<25:02:00, 39.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  7.822300434112549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/2295 [01:12<22:49:14, 35.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  7.3063788414001465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/2295 [01:47<22:28:12, 35.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  7.1335859298706055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/2295 [02:30<24:24:05, 38.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  7.106551647186279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/2295 [03:07<24:03:37, 37.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  6.986693859100342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 6/2295 [03:42<23:23:32, 36.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  7.133462905883789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 7/2295 [04:20<23:38:17, 37.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  6.655911922454834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 8/2295 [04:55<23:11:45, 36.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  6.70775032043457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 9/2295 [05:31<23:11:07, 36.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  6.532665252685547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 10/2295 [06:09<23:28:15, 36.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  6.239390850067139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 11/2295 [06:49<24:02:00, 37.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  6.43426513671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/2295 [07:28<24:09:58, 38.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  6.307568550109863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 13/2295 [08:04<23:49:05, 37.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  5.943945407867432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 14/2295 [08:41<23:38:07, 37.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  6.07077693939209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 15/2295 [09:20<24:02:24, 37.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  6.069853782653809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 16/2295 [09:59<24:10:33, 38.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  5.938697338104248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 17/2295 [10:36<23:52:24, 37.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  5.922584056854248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 18/2295 [11:11<23:28:52, 37.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  5.935183048248291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 19/2295 [11:48<23:20:10, 36.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss :  5.938259124755859\n"
     ]
    }
   ],
   "source": [
    "# Load base model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "base_model = GPT2Model.from_pretrained('gpt2')\n",
    "gpt2_config = base_model.config\n",
    "# 1. Patch single attention variant\n",
    "gqa_config = GQAConfig(\n",
    "        num_query_heads=gpt2_config.n_head,  # 12 for GPT-2 small\n",
    "        num_kv_heads=gpt2_config.n_head //3,  # Reduce KV heads by factor of 3\n",
    "        head_dim=gpt2_config.n_embd // gpt2_config.n_head,  # 768/12 = 64\n",
    "        dropout=gpt2_config.attn_pdrop\n",
    "    )\n",
    "\n",
    "print(gqa_config)\n",
    "\n",
    "flash_model = patch_attention_in_gpt2(base_model, GroupedQueryAttention,gqa_config)\n",
    "\n",
    "\n",
    "final_model = flash_model\n",
    "final_model = LanguageModelingWrapper(final_model)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n",
    "\n",
    "final_model.to(device)\n",
    "# Prepare data\n",
    "train_loader, eval_loader = prepare_wikitext2(tokenizer)\n",
    "\n",
    "optimizers =  AdamW(final_model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range (100):\n",
    "    train_epoch(final_model, train_loader, optimizers, device)\n",
    "    evaluate(final_model, eval_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto-feature",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
